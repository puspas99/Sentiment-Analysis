{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\puspa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\puspa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\puspa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\puspa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from spellchecker import SpellChecker\n",
    "import string \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Coronavirus_dec05.csv\")\n",
    "#check data have any  null value \n",
    "df.isnull().values.any()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop All Rows with any Null/NaN/NaT Values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12286, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12286, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplicates_removed = pd.DataFrame.drop_duplicates(df)\n",
    "\n",
    "df_duplicates_removed.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12286, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns = { '3': 'Tweet'}, inplace = False)\n",
    "df = df[[\"Tweet\"]]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @luvjuan: MayGODBlessAllSouls \\nHopePeace \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @MurtazaViews: PDM not permitted to hold De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @CBSLA: A restaurant owner who was forced t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @SuMoh7: WORTH READING IN FULL &amp;gt;&amp;gt;&amp;gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RT @Laurie_Garrett: Stellar, detailed reportin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet\n",
       "0  RT @luvjuan: MayGODBlessAllSouls \\nHopePeace \\...\n",
       "2  RT @MurtazaViews: PDM not permitted to hold De...\n",
       "3  RT @CBSLA: A restaurant owner who was forced t...\n",
       "4  RT @SuMoh7: WORTH READING IN FULL &gt;&gt;&gt;...\n",
       "9  RT @Laurie_Garrett: Stellar, detailed reportin..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentimenet lebeling\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_score(tweet):\n",
    "    # Calling the polarity_scores method on sid and passing in the text outputs a dictionary with negative, neutral, positive, and compound scores for the input text\n",
    "    text = \"'''\" + str(tweet) + \"'''\"\n",
    "    scores=sid.polarity_scores(text)   \n",
    "    return sentiment_lebel(scores[\"compound\"])\n",
    "\n",
    "def sentiment_lebel(score):\n",
    "    #-1 to -0.5 , -0.5 to 0 ,   0 to 0.5  ,   0.5 to  1\n",
    "    if score < -0.5 and score >= -1:\n",
    "     return \"Strongly Negative\"\n",
    "    elif score < 0 and score >= -0.5 :\n",
    "     return \"Negative\"\n",
    "    if score==0:\n",
    "     return \"Neutral\"\n",
    "    elif score >0 and score <= 0.5:\n",
    "     return \"Positive\"\n",
    "    elif score > 0.5 and score <= 1:\n",
    "     return \"Strongly Positive\"\n",
    "    else:\n",
    "     return \"NAN\"\n",
    "\n",
    "\n",
    "\n",
    "# function to convert numbers to words\n",
    "from num2words import num2words\n",
    "\n",
    "def num_to_words(text):\n",
    "    # splitting text into words with space\n",
    "    after_spliting = text.split()\n",
    "\n",
    "    for index in range(len(after_spliting)):\n",
    "        if after_spliting[index].isdigit():\n",
    "            after_spliting[index] = num2words(after_spliting[index])\n",
    "\n",
    "    # joining list into string with space\n",
    "    numbers_to_words = ' '.join(after_spliting)\n",
    "    return numbers_to_words\n",
    "\n",
    "# Remove punctuations\n",
    "\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(tweet):\n",
    "    return tweet.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "\n",
    "\n",
    "#Remove stopwords \n",
    "\n",
    "\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "STOPWORDS.remove(\"not\")\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "#stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "# spelling correction using spellchecker\n",
    "\n",
    "spell_corrector = SpellChecker()\n",
    "\n",
    "def spell_correction(text):\n",
    "    # initialize empty list to save correct spell words\n",
    "    correct_words = []\n",
    "    # extract spelling incorrect words by using unknown function of spellchecker\n",
    "    misSpelled_words = spell_corrector.unknown(text.split())\n",
    "\n",
    "    for each_word in text.split():\n",
    "        if each_word in misSpelled_words:\n",
    "            right_word = spell_corrector.correction(each_word)\n",
    "            correct_words.append(right_word)\n",
    "        else:\n",
    "            correct_words.append(each_word)\n",
    "\n",
    "    # joining correct_words list into single string\n",
    "    correct_spelling = ' '.join(correct_words)\n",
    "    return correct_spelling\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    \n",
    "    #Noise Removal\n",
    "    \n",
    "    #removing urls\n",
    "    sentence = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', sen)\n",
    "    \n",
    "    \n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sentence)\n",
    "    \n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    \n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    # Convert numbers to words\n",
    "    sentence = num_to_words(sentence)\n",
    "    \n",
    "    \n",
    "    # Remove punctuations\n",
    "    sentence =remove_punctuation(sentence)\n",
    "\n",
    "     # Remove stopwords\n",
    "    sentence =remove_stopwords(sentence)\n",
    "    \n",
    "    \n",
    "    #stemming \n",
    "    sentence =stem_words(sentence)\n",
    "    \n",
    "     # Removing RT \n",
    "    sentence=re.sub(r'RT','',sentence)\n",
    "    \n",
    "    #spell check\n",
    "    #sentence = spell_correction(sentence)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "sentences = list(df['Tweet'])\n",
    "for sen in sentences:\n",
    "    sentence=preprocess_text(sen)\n",
    "    y.append(sentiment_score(sentence))\n",
    "    sentiment_score(sen)\n",
    "    X.append(preprocess_text(sen))\n",
    "    \n",
    "\n",
    "my_df = {'Tweet': X,\n",
    "         'sentiment':y \n",
    "       } \n",
    "\n",
    "df = pd.DataFrame(my_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving df to csv\n",
    "df.to_csv('clean_data_dec05.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luvjuan maygodblessallsoul hopepeac grace peo...</td>\n",
       "      <td>Strongly Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>murtazaview pdm not permit hold dec thirteen ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbsla restaur owner forc shut coronaviru rest...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sumoh7 worth read IN full gtgtgt remdesivir c...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lauriegarrett stellar detail report florida g...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet          sentiment\n",
       "0   luvjuan maygodblessallsoul hopepeac grace peo...  Strongly Positive\n",
       "1   murtazaview pdm not permit hold dec thirteen ...            Neutral\n",
       "2   cbsla restaur owner forc shut coronaviru rest...           Negative\n",
       "3   sumoh7 worth read IN full gtgtgt remdesivir c...           Positive\n",
       "4   lauriegarrett stellar detail report florida g...           Positive"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
